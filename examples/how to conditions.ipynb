{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b0c422",
   "metadata": {},
   "source": [
    "# How to: Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e84203",
   "metadata": {},
   "source": [
    "Conditions are logic which runs on the check results in order to rate it as passing value or not passing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5924aa",
   "metadata": {},
   "source": [
    "In order to write conditions we first have to know what value a given check produces. Let's look at the check `DatasetsSizeComparison` and see it's return value in order to write condition for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd317ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': {'Size': 9}, 'Test': {'Size': 3}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepchecks.checks import DatasetsSizeComparison\n",
    "from deepchecks import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# TODO which data to load\n",
    "train_dataset = Dataset(pd.DataFrame(data={'x': [1,2,3,4,5,6,7,8,9]}))\n",
    "test_dataset = Dataset(pd.DataFrame(data={'x': [1,2,3]}))\n",
    "\n",
    "result = DatasetsSizeComparison().run(train_dataset, test_dataset)\n",
    "result.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c2566c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2946726201.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/tk/736pst9j1fv_15cs0whnv2l00000gn/T/ipykernel_34886/2946726201.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    To create condition we need to use the `add_condition` method of the check which accepts condition name and a function. this function receives the value of the `CheckResult` we defined in the `run` function and should return a boolean or `ConditionResult`\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "To create condition we need to use the `add_condition` method of the check which accepts condition name and a function. this function receives the value of the `CheckResult` we defined in the `run` function and should return a boolean or `ConditionResult`   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08900f1",
   "metadata": {},
   "outputs": [],
   "source": [
    " create a condition which validates the ratio between train and test sizes is inside a given range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks import Suite\n",
    "\n",
    "suite = Suite('custom suite',\n",
    "    DatasetSizeComparison().add_condition_ratio_is_between(0.5, 0.6)\n",
    ")\n",
    "\n",
    "suite.run(train_dataset, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
