{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470c3f6b",
   "metadata": {},
   "source": [
    "# Configure Check Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec4ed8",
   "metadata": {},
   "source": [
    "Conditions are logic which runs on the check results in order to rate it as passing or failing.\n",
    "\n",
    "- [Add Condition](#Add-Condition)\n",
    "- [Remove / Edit a Condition](#Remove-/-Edit-a-Condition)\n",
    "- [Add a Custom Condition](#Add-a-Custom-Condition)\n",
    "- [Set Custom Condition Category](#Set-Custom-Condition-Category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026760f",
   "metadata": {},
   "source": [
    "## Add Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c850e76",
   "metadata": {},
   "source": [
    "Most of Deepchecks' checks comes with option to add pre-defined conditions to them. To do so, each check class have methods in the name convention of `add_condition_x`, which adds to the check instance a ready condition. Each check instance can contains several conditions or none.  \n",
    "To create and add a custom condtition logic go to [Add a Custom Condition](#Add-a-Custom-Condition)\n",
    "\n",
    "For exmaple we will create a check and load pre-defined condition on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c8cc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetsSizeComparison\n",
       "\tConditions:\n",
       "\t\t0: Test dataset size is not smaller than 1000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepchecks.checks import DatasetsSizeComparison\n",
    "\n",
    "check = DatasetsSizeComparison().add_condition_test_size_not_smaller_than(1000)\n",
    "check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977fb8ec",
   "metadata": {},
   "source": [
    "## Remove / Edit a Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be40708",
   "metadata": {},
   "source": [
    "Deepchecks provides different kinds of default suites, which come with pre-defined conditions. You may want to remove a condition in case it isn't needed for you, or you may want to change the condition's parameters (since conditions functions are immutable).\n",
    "\n",
    "To remove a condition, start by printing the Suite and identifing the Check's ID, and the Condition's ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7bd116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Overfit Suite: [\n",
       "\t0: TrainTestDifferenceOverfit\n",
       "\t\tConditions:\n",
       "\t\t\t0: Train-Test metrics degradation ratio is not greater than 0.1\n",
       "\t1: BoostingOverfit(num_steps=20)\n",
       "\t\tConditions:\n",
       "\t\t\t0: Test score decline is not greater than 5.00%\n",
       "]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepchecks.suites import overfit_suite\n",
    "\n",
    "suite = overfit_suite()\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1da74",
   "metadata": {},
   "source": [
    "After we found the IDs we can remove the Condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf589a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Overfit Suite: [\n",
       "\t0: TrainTestDifferenceOverfit\n",
       "\t\tConditions:\n",
       "\t\t\t0: Train-Test metrics degradation ratio is not greater than 0.1\n",
       "\t1: BoostingOverfit(num_steps=20)\n",
       "]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access check by id\n",
    "check = suite[1]\n",
    "# Remove condition by id\n",
    "check.remove_condition(0)\n",
    "\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae06fd53",
   "metadata": {},
   "source": [
    "Now if we want we can also re-add the Condition using the built-in methods on the check, with a different parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9488c030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Overfit Suite: [\n",
       "\t0: TrainTestDifferenceOverfit\n",
       "\t\tConditions:\n",
       "\t\t\t0: Train-Test metrics degradation ratio is not greater than 0.1\n",
       "\t1: BoostingOverfit(num_steps=20)\n",
       "\t\tConditions:\n",
       "\t\t\t1: Test score decline is not greater than 20.00%\n",
       "]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-add the condition with new parameter\n",
    "check.add_condition_test_score_percent_decline_not_greater_than(0.2)\n",
    "\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b434c6",
   "metadata": {},
   "source": [
    "## Add a Custom Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73168e2e",
   "metadata": {},
   "source": [
    "In order to write conditions we first have to know what value a given check produces.  \n",
    "Let's look at the check `DatasetsSizeComparison` and see it's return value in order to write condition for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a1821bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': 9, 'Test': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepchecks.checks import DatasetsSizeComparison\n",
    "from deepchecks import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# We'll use dummy data for the purpose of this demonstration\n",
    "train_dataset = Dataset(pd.DataFrame(data={'x': [1,2,3,4,5,6,7,8,9]}))\n",
    "test_dataset = Dataset(pd.DataFrame(data={'x': [1,2,3]}))\n",
    "\n",
    "result = DatasetsSizeComparison().run(train_dataset, test_dataset)\n",
    "result.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08113761",
   "metadata": {},
   "source": [
    "Now we know the return value looks like. let's add a new condition that validates the ratio between train and test sizes is inside a given range.\n",
    "To create condition we need to use the `add_condition` method of the check which accepts condition name and a function. this function receives the value of the `CheckResult` that we saw above and should return a boolean or `ConditionResult`\n",
    "\n",
    "*Note: When implementing a condition in a custom check, you may want to add a method `add_condition_x()` to allow any consumer of your check to apply the condition (possibly with given parameters). For examples look at implemented Checks' source code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ef9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks import ConditionResult\n",
    "\n",
    "# Our parameters for the condition\n",
    "low_threshold = 0.4\n",
    "high_threshold = 0.6\n",
    "\n",
    "# Create the condition function\n",
    "def custom_condition(value: dict): \n",
    "    ratio = value['Test'] / value['Train']\n",
    "    if low_threshold <= ratio <= high_threshold:\n",
    "        return ConditionResult(True)\n",
    "    else:\n",
    "        # Note: if you doesn't care about the extra info, you can return directly a boolean\n",
    "        return ConditionResult(False, f'Test-Train ratio is {ratio:.2}')\n",
    "\n",
    "# Create the condition name\n",
    "condition_name = f'Test-Train ratio is between {low_threshold} to {high_threshold}'\n",
    "\n",
    "# Create check instance with the condition \n",
    "check = DatasetsSizeComparison().add_condition(condition_name, custom_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c194fdd",
   "metadata": {},
   "source": [
    "Now we will use a Suite to demonstrate the action of the condition, since the suite runs the condition for us automatically and print it in a stylish way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b8606b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Suite for Condition:   0%|          | 0/1 [00:00<?, ? Check/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <h1>Suite for Condition</h1>\n",
       "    <p>The suite is composed of various checks such as: Datasets Size Comparison, etc...<br>\n",
       "    Each check may contain conditions (which results in \n",
       "    <span style=\"color: green;display:inline-block\">✓</span> /\n",
       "    <span style=\"color: red;display:inline-block\">✖</span> /\n",
       "    <span style=\"color: orange;font-weight:bold;display:inline-block\">!</span>\n",
       "    ), as well as other outputs such as plots or tables.<br>\n",
       "    Suites, checks and conditions can all be modified (see tutorial [link]).</p>\n",
       "    <hr style=\"background-color: black;border: 0 none;color: black;height: 1px;\"><h2>Conditions Summary</h2>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_7e9ff_ table,thead,tbody,th,td {\n",
       "          text-align: left;\n",
       "    }</style><table id=\"T_7e9ff_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Status</th>        <th class=\"col_heading level0 col1\" >Check</th>        <th class=\"col_heading level0 col2\" >Condition</th>        <th class=\"col_heading level0 col3\" >More Info</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_7e9ff_row0_col0\" class=\"data row0 col0\" ><div style=\"color: red;text-align: center\">✖</div></td>\n",
       "                        <td id=\"T_7e9ff_row0_col1\" class=\"data row0 col1\" >Datasets Size Comparison</td>\n",
       "                        <td id=\"T_7e9ff_row0_col2\" class=\"data row0 col2\" >Test-Train ratio is between 0.4 to 0.6</td>\n",
       "                        <td id=\"T_7e9ff_row0_col3\" class=\"data row0 col3\" >Test-Train ratio is 0.33</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr style=\"background-color: black;border: 0 none;color: black;height: 1px;\"><h2>Additional Outputs</h2>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Datasets Size Comparison</h4>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Verify test dataset size comparing it to the train dataset size.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_4027a_ table,thead,tbody,th,td {\n",
       "          text-align: left;\n",
       "    }</style><table id=\"T_4027a_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Train</th>        <th class=\"col_heading level0 col1\" >Test</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4027a_level0_row0\" class=\"row_heading level0 row0\" >Size</th>\n",
       "                        <td id=\"T_4027a_row0_col0\" class=\"data row0 col0\" >9</td>\n",
       "                        <td id=\"T_4027a_row0_col1\" class=\"data row0 col1\" >3</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks import Suite\n",
    "\n",
    "# Using suite to run check & condition\n",
    "suite = Suite('Suite for Condition',\n",
    "    check\n",
    ")\n",
    "\n",
    "suite.run(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a44dfe9",
   "metadata": {},
   "source": [
    "----------------\n",
    "## Set Custom Condition Category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd9790",
   "metadata": {},
   "source": [
    "When writing your own condition logic, you can decide to mark a condition result as either fail or warn, by passing the category to the `ConditionResult` object.\n",
    "For example we can even write condition which sets the category based on severity of the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b25277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks import ConditionResult, ConditionCategory\n",
    "\n",
    "# Our parameters for the condition\n",
    "low_threshold = 0.3\n",
    "high_threshold = 0.7\n",
    "\n",
    "# Create the condition function for check `DatasetsSizeComparison`\n",
    "def custom_condition(value: dict): \n",
    "    ratio = value['Test'] / value['Train']\n",
    "    if low_threshold <= ratio <= high_threshold:\n",
    "        return ConditionResult(True)\n",
    "    elif ratio < low_threshold:\n",
    "        return ConditionResult(False, f'Test-Train ratio is {ratio:.2}', ConditionCategory.FAIL)\n",
    "    else:\n",
    "        return ConditionResult(False, f'Test-Train ratio is {ratio:.2}', ConditionCategory.WARN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
