{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "159fde75",
   "metadata": {},
   "source": [
    "# Configure Check Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6409ccb",
   "metadata": {},
   "source": [
    "Conditions are logic which runs on the check results in order to rate it as passing value or not passing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d760c3",
   "metadata": {},
   "source": [
    "## Edit Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e66d9",
   "metadata": {},
   "source": [
    "Deepchecks provides different kind of default suites, which comes with built-in conditions. You may want to remove a condition in case it isn't needed for you, or you want to change the parameters (since conditions functions are immutable).\n",
    "\n",
    "To remove condition, start with printing the Suite and identifing the Check's ID, and the Condition's ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ca74b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Overfit Suite: [\n",
       "\t0: TrainTestDifferenceOverfit\n",
       "\t\tConditions:\n",
       "\t\t\t0: Train-Test metrics degradation ratio is not greater than 0.1\n",
       "\t1: BoostingOverfit(num_steps=20)\n",
       "\t\tConditions:\n",
       "\t\t\t0: Test score decline is not greater than 5.00%\n",
       "]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepchecks.suites import overfit_suite\n",
    "\n",
    "suite = overfit_suite()\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df93121",
   "metadata": {},
   "source": [
    "After we found the IDs we can remove the Condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40097660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Overfit Suite: [\n",
       "\t0: TrainTestDifferenceOverfit\n",
       "\t\tConditions:\n",
       "\t\t\t0: Train-Test metrics degradation ratio is not greater than 0.1\n",
       "\t1: BoostingOverfit(num_steps=20)\n",
       "]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access check by id\n",
    "check = suite[1]\n",
    "# Remove condition by id\n",
    "check.remove_condition(0)\n",
    "\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035728e4",
   "metadata": {},
   "source": [
    "Now if we want we can also re-add the Condition using the built-in methods on the check, with a different parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c01c802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Overfit Suite: [\n",
       "\t0: TrainTestDifferenceOverfit\n",
       "\t\tConditions:\n",
       "\t\t\t0: Train-Test metrics degradation ratio is not greater than 0.1\n",
       "\t1: BoostingOverfit(num_steps=20)\n",
       "\t\tConditions:\n",
       "\t\t\t1: Test score decline is not greater than 20.00%\n",
       "]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-add the condition with new parameter\n",
    "check.add_condition_test_score_percent_decline_not_greater_than(0.2)\n",
    "\n",
    "suite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced79c03",
   "metadata": {},
   "source": [
    "## Add a Custom Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010e05a",
   "metadata": {},
   "source": [
    "In order to write conditions we first have to know what value a given check produces.  \n",
    "Let's look at the check `DatasetsSizeComparison` and see it's return value in order to write condition for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "326995f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': 9, 'Test': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepchecks.checks import DatasetsSizeComparison\n",
    "from deepchecks import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# We'll use dummy data for the purpose of this demonstration\n",
    "train_dataset = Dataset(pd.DataFrame(data={'x': [1,2,3,4,5,6,7,8,9]}))\n",
    "test_dataset = Dataset(pd.DataFrame(data={'x': [1,2,3]}))\n",
    "\n",
    "result = DatasetsSizeComparison().run(train_dataset, test_dataset)\n",
    "result.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59050aaf",
   "metadata": {},
   "source": [
    "Now we know the return value looks like. let's add a new condition that validates the ratio between train and test sizes is inside a given range.\n",
    "To create condition we need to use the `add_condition` method of the check which accepts condition name and a function. this function receives the value of the `CheckResult` that we saw above and should return a boolean or `ConditionResult`\n",
    "\n",
    "*Note: When implementing a condition in a custom check, you may want to add a method `add_condition_x()` to allow any consumer of your check to apply the condition (possibly with given parameters). For examples look at implemented Checks' source code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8bd859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks import ConditionResult\n",
    "\n",
    "# Our parameters for the condition\n",
    "low_threshold = 0.4\n",
    "high_threshold = 0.6\n",
    "\n",
    "# Create the condition function\n",
    "def custom_condition(value: dict): \n",
    "    ratio = value['Test'] / value['Train']\n",
    "    if low_threshold <= ratio <= high_threshold:\n",
    "        return ConditionResult(True)\n",
    "    else:\n",
    "        # Note: if you doesn't care about the extra info, you can return directly a boolean\n",
    "        return ConditionResult(False, f'Test-Train ratio is {ratio:.2}')\n",
    "\n",
    "# Create the condition name\n",
    "condition_name = f'Test-Train ratio is between {low_threshold} to {high_threshold}'\n",
    "\n",
    "# Create check instance with the condition \n",
    "check = DatasetsSizeComparison().add_condition(condition_name, custom_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe65f59",
   "metadata": {},
   "source": [
    "Now we will use Suite to demonstrate the action of the condition, since the suite runs the condition for us automaticlly and print it in a stylish way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9c698c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Suite for Condition:   0%|          | 0/1 [00:00<?, ? Check/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <h1>Suite for Condition</h1>\n",
       "    <p>The suite is composed of various checks such as: Datasets Size Comparison, etc...<br>\n",
       "    Each check may contain conditions (which results in \n",
       "    <span style=\"color: green;display:inline-block\">✓</span> /\n",
       "    <span style=\"color: red;display:inline-block\">✖</span> /\n",
       "    <span style=\"color: orange;font-weight:bold;display:inline-block\">!</span>\n",
       "    ), as well as other outputs such as plots or tables.<br>\n",
       "    Suites, checks and conditions can all be modified (see tutorial [link]).</p>\n",
       "    <hr style=\"background-color: black;border: 0 none;color: black;height: 1px;\"><h2>Conditions Summary</h2>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_7e9ff_ table,thead,tbody,th,td {\n",
       "          text-align: left;\n",
       "    }</style><table id=\"T_7e9ff_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Status</th>        <th class=\"col_heading level0 col1\" >Check</th>        <th class=\"col_heading level0 col2\" >Condition</th>        <th class=\"col_heading level0 col3\" >More Info</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_7e9ff_row0_col0\" class=\"data row0 col0\" ><div style=\"color: red;text-align: center\">✖</div></td>\n",
       "                        <td id=\"T_7e9ff_row0_col1\" class=\"data row0 col1\" >Datasets Size Comparison</td>\n",
       "                        <td id=\"T_7e9ff_row0_col2\" class=\"data row0 col2\" >Test-Train ratio is between 0.4 to 0.6</td>\n",
       "                        <td id=\"T_7e9ff_row0_col3\" class=\"data row0 col3\" >Test-Train ratio is 0.33</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr style=\"background-color: black;border: 0 none;color: black;height: 1px;\"><h2>Additional Outputs</h2>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Datasets Size Comparison</h4>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Verify test dataset size comparing it to the train dataset size.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_4027a_ table,thead,tbody,th,td {\n",
       "          text-align: left;\n",
       "    }</style><table id=\"T_4027a_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Train</th>        <th class=\"col_heading level0 col1\" >Test</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4027a_level0_row0\" class=\"row_heading level0 row0\" >Size</th>\n",
       "                        <td id=\"T_4027a_row0_col0\" class=\"data row0 col0\" >9</td>\n",
       "                        <td id=\"T_4027a_row0_col1\" class=\"data row0 col1\" >3</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks import Suite\n",
    "\n",
    "# Using suite to run check & condition\n",
    "suite = Suite('Suite for Condition',\n",
    "    check\n",
    ")\n",
    "\n",
    "suite.run(train_dataset, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
