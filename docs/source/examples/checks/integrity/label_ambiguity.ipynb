{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06bdcdfc",
   "metadata": {},
   "source": [
    "# Label Ambiguity \n",
    "This notebooks provides an overview for using and understanding the label ambiguity check.\n",
    "\n",
    "**Structure:**\n",
    "\n",
    "- [What is Label Ambiguity?](#what_is_label_ambiguity)\n",
    "- [Load data](#load_data_model)\n",
    "- [Run the check](#run_check)\n",
    "- [Define a condition](#define_condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff805f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T16:41:12.256403Z",
     "iopub.status.busy": "2022-01-19T16:41:12.255668Z",
     "iopub.status.idle": "2022-01-19T16:41:14.210623Z",
     "shell.execute_reply": "2022-01-19T16:41:14.211259Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepchecks.checks.integrity import LabelAmbiguity\n",
    "from deepchecks.base import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a469ddae",
   "metadata": {},
   "source": [
    "<a id='what_is_label_ambiguity'></a>\n",
    "## What is Label Ambiguity?\n",
    "\n",
    "Label Ambiguity searches for identical samples with different labels. This can occur due to either mislabeled data, or when the data collected is missing features necessary to separate the labels. If the data is mislabled, it can confuse the model and can result in lower performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e1979f",
   "metadata": {},
   "source": [
    "<a id='load_data_model'></a>\n",
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb1f4da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T16:41:14.219286Z",
     "iopub.status.busy": "2022-01-19T16:41:14.218623Z",
     "iopub.status.idle": "2022-01-19T16:41:14.220417Z",
     "shell.execute_reply": "2022-01-19T16:41:14.220958Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatically inferred these columns as categorical features: numParams, num_%20, num_@. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepchecks.datasets.classification.phishing import load_data\n",
    "\n",
    "phishing_dataframe = load_data(as_train_test=False, data_format='Dataframe')\n",
    "phishing_dataset = Dataset(phishing_dataframe, label='target', features=['urlLength', 'numDigits', 'numParams', 'num_%20', 'num_@', 'bodyLength', 'numTitles', 'numImages', 'numLinks', 'specialChars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6cc03c",
   "metadata": {},
   "source": [
    "<a id='run_check'></a>\n",
    "\n",
    "## Run the check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d3c08a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T16:41:14.239204Z",
     "iopub.status.busy": "2022-01-19T16:41:14.238606Z",
     "iopub.status.idle": "2022-01-19T16:41:14.241234Z",
     "shell.execute_reply": "2022-01-19T16:41:14.241615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Label Ambiguity</h4><p>Find samples with multiple labels. <a href=\"https://docs.deepchecks.com/en/0.3.2/examples/checks/integrity/label_ambiguity.html?utm_source=display_output&utm_medium=referral&utm_campaign=check_link\" target=\"_blank\">Read More...</a></p><h5>Additional Outputs</h5><div>Each row in the table shows an example of a data sample and the its observed labels as found in the dataset. Showing top 5 of 17</div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlLength</th>\n",
       "      <th>numDigits</th>\n",
       "      <th>numParams</th>\n",
       "      <th>num_%20</th>\n",
       "      <th>num_@</th>\n",
       "      <th>bodyLength</th>\n",
       "      <th>numTitles</th>\n",
       "      <th>numImages</th>\n",
       "      <th>numLinks</th>\n",
       "      <th>specialChars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observed Labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LabelAmbiguity().run(phishing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc05f00",
   "metadata": {},
   "source": [
    "We can also check label ambiguity on a subset of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebb6be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Label Ambiguity</h4><p>Find samples with multiple labels. <a href=\"https://docs.deepchecks.com/en/0.3.2/examples/checks/integrity/label_ambiguity.html?utm_source=display_output&utm_medium=referral&utm_campaign=check_link\" target=\"_blank\">Read More...</a></p><h5>Additional Outputs</h5><div>Each row in the table shows an example of a data sample and the its observed labels as found in the dataset. Showing top 5 of 78</div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlLength</th>\n",
       "      <th>numDigits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observed Labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LabelAmbiguity(columns=['urlLength', 'numDigits']).run(phishing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a46a42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T16:41:14.286024Z",
     "iopub.status.busy": "2022-01-19T16:41:14.285108Z",
     "iopub.status.idle": "2022-01-19T16:41:14.286932Z",
     "shell.execute_reply": "2022-01-19T16:41:14.287452Z"
    }
   },
   "source": [
    "<a id='define_condition'></a>\n",
    "\n",
    "## Define a condition\n",
    "\n",
    "Now, we define a condition that enforces that the ratio of ambiguous samples should be 0. A condition is deepchecks' way to validate model and data quality, and let you know if anything goes wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5f06ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T16:41:14.297988Z",
     "iopub.status.busy": "2022-01-19T16:41:14.296998Z",
     "iopub.status.idle": "2022-01-19T16:41:14.300181Z",
     "shell.execute_reply": "2022-01-19T16:41:14.300701Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Label Ambiguity</h4><p>Find samples with multiple labels. <a href=\"https://docs.deepchecks.com/en/0.3.2/examples/checks/integrity/label_ambiguity.html?utm_source=display_output&utm_medium=referral&utm_campaign=check_link\" target=\"_blank\">Read More...</a></p><h5>Conditions Summary</h5><style type=\"text/css\">\n",
       "#T_cab6f_ table {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_cab6f_ thead {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_cab6f_ tbody {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_cab6f_ th {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_cab6f_ td {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cab6f_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >Status</th>\n",
       "      <th class=\"col_heading level0 col1\" >Condition</th>\n",
       "      <th class=\"col_heading level0 col2\" >More Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_cab6f_row0_col0\" class=\"data row0 col0\" ><div style=\"color: red;text-align: center\">✖</div></td>\n",
       "      <td id=\"T_cab6f_row0_col1\" class=\"data row0 col1\" >Ambiguous sample ratio is not greater than 0%</td>\n",
       "      <td id=\"T_cab6f_row0_col2\" class=\"data row0 col2\" >Found ratio of samples with multiple labels above threshold: 0.6%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check = LabelAmbiguity()\n",
    "check.add_condition_ambiguous_sample_ratio_not_greater_than(0)\n",
    "result = check.run(phishing_dataset)\n",
    "result.show(show_additional_outputs=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
