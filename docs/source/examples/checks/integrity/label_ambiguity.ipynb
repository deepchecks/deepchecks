{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06bdcdfc",
   "metadata": {},
   "source": [
    "# Label Ambiguity \n",
    "This notebooks provides an overview for using and understanding the label ambiguity check.\n",
    "\n",
    "**Structure:**\n",
    "\n",
    "- [What is Label Ambiguity?](#what_is_label_ambiguity)\n",
    "- [Load data](#load_data_model)\n",
    "- [Run the check](#run_check)\n",
    "- [Define a condition](#define_condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff805f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T16:41:12.256403Z",
     "iopub.status.busy": "2022-01-19T16:41:12.255668Z",
     "iopub.status.idle": "2022-01-19T16:41:14.210623Z",
     "shell.execute_reply": "2022-01-19T16:41:14.211259Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepchecks.checks.integrity import LabelAmbiguity\n",
    "from deepchecks.base import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a0b135",
   "metadata": {},
   "source": [
    "<a id='what_is_label_ambiguity'></a>\n",
    "## What is Label Ambiguity?\n",
    "\n",
    "Label Ambiguity searches for identical samples with different labels. This can occur due to either mislabeled data, or when the data collected is missing features necessary to separate the labels. If the data is mislabled, it can confuse the model and can result in lower performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16eb080",
   "metadata": {},
   "source": [
    "<a id='load_data_model'></a>\n",
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb1f4da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T16:41:14.219286Z",
     "iopub.status.busy": "2022-01-19T16:41:14.218623Z",
     "iopub.status.idle": "2022-01-19T16:41:14.220417Z",
     "shell.execute_reply": "2022-01-19T16:41:14.220958Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatically inferred these columns as categorical features: numParams, num_%20, num_@. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepchecks.datasets.classification.phishing import load_data\n",
    "\n",
    "phishing_dataframe = load_data(as_train_test=False, data_format='Dataframe')\n",
    "phishing_dataset = Dataset(phishing_dataframe, label='target', features=['urlLength', 'numDigits', 'numParams', 'num_%20', 'num_@', 'bodyLength', 'numTitles', 'numImages', 'numLinks', 'specialChars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14549212",
   "metadata": {},
   "source": [
    "<a id='run_check'></a>\n",
    "\n",
    "## Run the check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d3c08a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T16:41:14.239204Z",
     "iopub.status.busy": "2022-01-19T16:41:14.238606Z",
     "iopub.status.idle": "2022-01-19T16:41:14.241234Z",
     "shell.execute_reply": "2022-01-19T16:41:14.241615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Label Ambiguity</h4><p>Find samples with multiple labels. <a href=\"https://docs.deepchecks.com/en/0.3.2/examples/checks/integrity/label_ambiguity.html?utm_source=display_output&utm_medium=referral&utm_campaign=check_link\" target=\"_blank\">Read More...</a></p><h5>Additional Outputs</h5><div>Each row in the table shows an example of a data sample and the its observed labels as found in the dataset.</div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlLength</th>\n",
       "      <th>numDigits</th>\n",
       "      <th>numParams</th>\n",
       "      <th>num_%20</th>\n",
       "      <th>num_@</th>\n",
       "      <th>bodyLength</th>\n",
       "      <th>numTitles</th>\n",
       "      <th>numImages</th>\n",
       "      <th>numLinks</th>\n",
       "      <th>specialChars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observed Labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LabelAmbiguity().run(phishing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f686464",
   "metadata": {},
   "source": [
    "We can also check label ambiguity on a subset of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725a064e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Label Ambiguity</h4><p>Find samples with multiple labels. <a href=\"https://docs.deepchecks.com/en/0.3.2/examples/checks/integrity/label_ambiguity.html?utm_source=display_output&utm_medium=referral&utm_campaign=check_link\" target=\"_blank\">Read More...</a></p><h5>Additional Outputs</h5><div>Each row in the table shows an example of a data sample and the its observed labels as found in the dataset.</div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlLength</th>\n",
       "      <th>numDigits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observed Labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LabelAmbiguity(columns=['urlLength', 'numDigits']).run(phishing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf84f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T16:41:14.286024Z",
     "iopub.status.busy": "2022-01-19T16:41:14.285108Z",
     "iopub.status.idle": "2022-01-19T16:41:14.286932Z",
     "shell.execute_reply": "2022-01-19T16:41:14.287452Z"
    }
   },
   "source": [
    "<a id='define_condition'></a>\n",
    "\n",
    "## Define a condition\n",
    "\n",
    "Now, we define a condition that enforce the ratio of ambigous samples to be 0. A condition is deepchecks' way to validate model and data quality, and let you know if anything goes wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5f06ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T16:41:14.297988Z",
     "iopub.status.busy": "2022-01-19T16:41:14.296998Z",
     "iopub.status.idle": "2022-01-19T16:41:14.300181Z",
     "shell.execute_reply": "2022-01-19T16:41:14.300701Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Label Ambiguity</h4><p>Find samples with multiple labels. <a href=\"https://docs.deepchecks.com/en/0.3.2/examples/checks/integrity/label_ambiguity.html?utm_source=display_output&utm_medium=referral&utm_campaign=check_link\" target=\"_blank\">Read More...</a></p><h5>Conditions Summary</h5><style type=\"text/css\">\n",
       "#T_86594_ table {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_86594_ thead {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_86594_ tbody {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_86594_ th {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_86594_ td {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_86594_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >Status</th>\n",
       "      <th class=\"col_heading level0 col1\" >Condition</th>\n",
       "      <th class=\"col_heading level0 col2\" >More Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_86594_row0_col0\" class=\"data row0 col0\" ><div style=\"color: red;text-align: center\">âœ–</div></td>\n",
       "      <td id=\"T_86594_row0_col1\" class=\"data row0 col1\" >Ambiguous sample ratio is not greater than 0%</td>\n",
       "      <td id=\"T_86594_row0_col2\" class=\"data row0 col2\" >Found ratio of samples with multiple labels above threshold: 0.6%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check = LabelAmbiguity()\n",
    "check.add_condition_ambiguous_sample_ratio_not_greater_than(0)\n",
    "result = check.run(phishing_dataset)\n",
    "result.show(show_additional_outputs=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
