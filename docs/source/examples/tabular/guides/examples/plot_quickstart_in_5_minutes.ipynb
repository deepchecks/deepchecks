{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quickstart in 5 minutes\n=======================\n\nIn order to run your first Deepchecks Suite all you need to have is the\ndata and model that you wish to validate. More specifically, you need:\n\n-   Your train and test data (in Pandas DataFrames or Numpy Arrays)\n-   (optional) A [supported\n    model](/user-guide/tabular/supported_models.rst) (including XGBoost,\n    scikit-learn models, and many more). Required for running checks\n    that need the model\\'s predictions for running.\n\nTo run your first suite on your data and model, you need only a few\nlines of code, that start here: [Define a Dataset\nObject](#define-a-dataset-object).\n\n\\# If you don\\'t have deepchecks installed yet:\n\n``` {.sourceCode .python}\n# If you don't have deepchecks installed yet:\nimport sys\n!{sys.executable} -m pip install deepchecks -U --quiet #--user\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Data, Split Train-Val, and Train a Simple Model\n====================================================\n\nFor the purpose of this guide we\\'ll use the simple iris dataset and\ntrain a simple random forest model for multiclass classification:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# General imports\nimport pandas as pd\nimport numpy as np\n\nfrom deepchecks.tabular.datasets.classification import iris\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\n# Load Data\niris_df = iris.load_data(data_format='Dataframe', as_train_test=False)\nlabel_col = 'target'\ndf_train, df_test = train_test_split(iris_df, stratify=iris_df[label_col], random_state=0)\n\n# Train Model\nrf_clf = RandomForestClassifier()\nrf_clf.fit(df_train.drop(label_col, axis=1), df_train[label_col]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a Dataset Object\n=======================\n\nInitialize the Dataset object, stating the relevant metadata about the\ndataset (e.g. the name for the label column)\n\nCheck out the Dataset\\'s attributes to see which additional special\ncolumns can be declared and used (e.g. date column, index column).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular import Dataset\n\n# We explicitly state that this dataset has no categorical features, otherwise they will be automatically inferred\n# If the dataset has categorical features, the best practice is to pass a list with their names\n\nds_train = Dataset(df_train, label=label_col, cat_features=[])\nds_test =  Dataset(df_test,  label=label_col, cat_features=[])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run a Deepchecks Suite\n======================\n\nRun the full suite\n------------------\n\nUse the `full_suite` that is a collection of (most of) the prebuilt\nchecks.\n\nCheck out the [when should you\nuse](/user-guide/concepts/when_should_you_use.rst) deepchecks guide for\nsome more info about the existing suites and when to use them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.suites import full_suite\n\nsuite = full_suite()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "suite.run(train_dataset=ds_train, test_dataset=ds_test, model=rf_clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the integrity suite\n=======================\n\nIf you still haven\\'t started modeling and just have a single dataset,\nyou can use the `single_dataset_integrity`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.suites import single_dataset_integrity\n\ninteg_suite = single_dataset_integrity()\ninteg_suite.run(ds_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run a Deepchecks Check\n======================\n\nIf you want to run a specific check, you can just import it and run it\ndirectly.\n\nCheck out the [Check Demonstrations](/examples/tabular/checks/index.rst)\nin the examples or the [API Reference](/api/index.rst) for more info\nabout the existing checks and their parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.checks import TrainTestLabelDrift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = TrainTestLabelDrift()\nresult = check.run(ds_train, ds_test)\nresult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\%% and also inspect the result value which has a check-dependant\nstructure:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Edit an Existing Suite\n======================\n\nInspect suite and remove condition\n----------------------------------\n\nWe can see that the single feature contribution failed, both for test\nand for train. Since this is a very simple dataset with few features and\nthis behavior is not necessarily problematic, we will remove the\nexisting conditions for the PPS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Lets first print the suite to find the conditions that we want to change:\n\nsuite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# now we can use the check's index and the condition's number to remove it:\nprint(suite[6])\nsuite[6].remove_condition(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# print and see that the condition was removed\nsuite[6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we now re-run the suite, all of the existing conditions will pass.\n\n*Note: the check we manipulated will still run as part of the Suite,\nhowever it won\\'t appear in the Conditions Summary since it no longer\nhas any conditions defined on it. You can still see its display results\nin the Additional Outputs section*\n\n**For more info about working with conditions, see the detailed\nconfiguring conditions guide.**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}