{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Whole Dataset Drift\n===================\n\nThis notebooks provides an overview for using and understanding the\nwhole dataset drift check.\n\n**Structure:**\n\n-   [What is a dataset drift?](#what-is-a-dataset-drift)\n-   [Loading the Data](#loading-the-data)\n-   [Run the check](#run-the-check)\n-   [Define a condition](#define-a-condition)\n\nWhat is a dataset drift?\n------------------------\n\nA whole dataset drift, or a multivariate dataset drift, occurs when the\nstatistical properties of our input feature change, denoted by a change\nin the distribution P(X).\n\nCauses of data drift include:\n\n-   Upstream process changes, such as a sensor being replaced that\n    changes the units of measurement from inches to centimeters.\n-   Data quality issues, such as a broken sensor always reading 0.\n-   Natural drift in the data, such as mean temperature changing with\n    the seasons.\n-   Change in relation between features, or covariate shift.\n\nThe difference between a [feature\ndrift](https://docs.deepchecks.com/en/stable/examples/checks/distribution/train_test_feature_drift.html)\n(or univariate dataset drift) and a multivariate drift is that in the\nlatter the data drift occures in more that one feature.\n\nIn the context of machine learning, drift between the training set and\nthe test means that the model was trained on data that is different from\nthe current test data, thus it will probably make more mistakes\npredicting the target variable.\n\n### How deepchecks detects dataset drift\n\nThere are many methods to detect feature drift. Some of them are\nstatistical methods that aim to measure difference between distribution\nof 2 given sets. This methods are more suited to univariate\ndistributions and are primarily used to detect drift between 2 subsets\nof a single feature.\n\nMeasuring a multivariate data drift is a bit more challenging. In the\nwhole dataset drift check, the multivariate drift is measured by\ntraining a classifier that detects which samples come from a known\ndistribution and defines the drift by the accuracy of this classifier.\n\nPractically, the check concatanates the train and the test sets, and\nassigns label 0 to samples that come from the training set, and 1 to\nthose who are from the test set. Then, we train a binary classifer of\ntype [Histogram-based Gradient Boosting Classification\nTree](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html),\nand measure the drift score from the AUC score of this classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading the Data\n================\n\nThe dataset is the adult dataset which can be downloaded from the UCI\nmachine learning repository.\n\nDua, D. and Graff, C. (2019). UCI Machine Learning Repository\n\\[<http://archive.ics.uci.edu/ml>\\]. Irvine, CA: University of\nCalifornia, School of Information and Computer Science.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nfrom urllib.request import urlopen\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\n\nname_data = urlopen('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names')\nlines = [l.decode(\"utf-8\") for l in name_data if ':' in l.decode(\"utf-8\") and '|' not in l.decode(\"utf-8\")]\n\nfeatures = [l.split(':')[0] for l in lines]\nlabel_name = 'income'\n\ncat_features = [l.split(':')[0] for l in lines if 'continuous' not in l]\n\ntrain_df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',\n                       names=features + [label_name])\ntest_df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test',\n                      names=features + [label_name], skiprows=1)\n\ntest_df[label_name] = test_df [label_name].str[:-1]\n\nencoder = LabelEncoder()\nencoder.fit(train_df[label_name])\ntrain_df[label_name] = encoder.transform(train_df[label_name])\ntest_df[label_name] = encoder.transform(test_df[label_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Process into dataset\n====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular import Dataset\n\ncat_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', \n                'race', 'sex', 'native-country']\ntrain_ds = Dataset(train_df, label=label_name, cat_features=cat_features)\ntest_ds = Dataset(test_df, label=label_name, cat_features=cat_features)\n\nnumeric_features = list(set(train_ds.features) - set(cat_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_ds.label_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.checks import WholeDatasetDrift\n\ncheck = WholeDatasetDrift()\ncheck.run(train_dataset=train_ds, test_dataset=test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that there is almost no drift found between the train and the\ntest set of the raw adult dataset. In addition to the drift score the\ncheck displays the top features that contibuted to the data drift.\n\nIntroduce drift to dataset\n==========================\n\nNow, let\\'s try to add a manual data drift to the data by sampling a\nbiased portion of the training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sample_size = 10000\nrandom_seed = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_drifted_df = pd.concat([train_ds.data.sample(min(sample_size, train_ds.n_samples) - 5000, random_state=random_seed), \n                             train_ds.data[train_ds.data['sex'] == ' Female'].sample(5000, random_state=random_seed)])\ntest_drifted_df = test_ds.data.sample(min(sample_size, test_ds.n_samples), random_state=random_seed)\n\ntrain_drifted_ds = Dataset(train_drifted_df, label=label_name, cat_features=cat_features)\ntest_drifted_ds = Dataset(test_drifted_df, label=label_name, cat_features=cat_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = WholeDatasetDrift()\ncheck.run(train_dataset=train_drifted_ds, test_dataset=test_drifted_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the check detects a multivariate drift between the train\nand the test sets. It also displays the sex feature\\'s distribution -\nthe feature that contributed the most to that drift. This is reasonable\nsince the sampling was biased based on that feature.\n\nDefine a condition\n==================\n\nNow, we define a condition that enforce the whole dataset drift score\nmust be below 0.1. A condition is deepchecks\\' way to validate model and\ndata quality, and let you know if anything goes wrong.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = WholeDatasetDrift()\ncheck.add_condition_overall_drift_value_not_greater_than(0.1)\ncheck.run(train_dataset=train_drifted_ds, test_dataset=test_drifted_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we see, our condition successfully detects the drift score is above\nthe defined threshold.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}