{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Duplicates\n===============\n\nThis notebooks provides an overview for using and understanding the data\nduplicates check:\n\n**Structure:**\n\n-   [Why data duplicates?](#why-data-duplicates)\n-   [Load Data](#load-data)\n-   [Run the Check](#run-the-check)\n-   [Define a Condition](#define-a-condition)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.checks.integrity.data_duplicates import DataDuplicates\nfrom deepchecks.tabular import Dataset, Suite\nfrom datetime import datetime\nimport pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Why data duplicates?\n====================\n\nThe `DataDuplicates` check finds multiple instances of identical samples\nin the Dataset. Duplicate samples increase the weight the model gives to\nthose samples. If these duplicates are there intentionally (e.g. as a\nresult of intentional oversampling, or due to the dataset\\'s nature it\nhas identical-looking samples) this may be valid, however if this is an\nhidden issue we\\'re not expecting to occur, it may be an indicator for a\nproblem in the data pipeline that requires attention.\n\nLoad Data\n=========\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.datasets.classification.phishing import load_data\n\nphishing_dataset = load_data(as_train_test=False, data_format='DataFrame')\nphishing_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the Check\n=============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.checks import DataDuplicates\nDataDuplicates().run(phishing_dataset)\n\n# With Check Parameters\n# ---------------------\n# ``DataDuplicates`` check can also use a specific subset of columns (or alternatively\n# use all columns except specific ignore_columns to check duplication):\n\nDataDuplicates(columns=[\"entropy\", \"numParams\"]).run(phishing_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "DataDuplicates(ignore_columns=[\"scrape_date\"], n_to_show=10).run(phishing_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a Condition\n==================\n\nNow, we define a condition that enforce the ratio of duplicates to be 0.\nA condition is deepchecks\\' way to validate model and data quality, and\nlet you know if anything goes wrong.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = DataDuplicates()\ncheck.add_condition_ratio_not_greater_than(0)\nresult = check.run(phishing_dataset)\nresult.show(show_additional_outputs=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}