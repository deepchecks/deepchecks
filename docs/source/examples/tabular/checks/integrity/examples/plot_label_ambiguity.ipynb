{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Label Ambiguity\n===============\n\nThis notebooks provides an overview for using and understanding the\nlabel ambiguity check.\n\n**Structure:**\n\n-   [What is Label Ambiguity?](#what-is-label-ambiguity)\n-   [Load Data](#load-data)\n-   [Run the Check](#run-the-check)\n-   [Define a Condition](#define-a-condition)\n\nWhat is Label Ambiguity?\n------------------------\n\nLabel Ambiguity searches for identical samples with different labels.\nThis can occur due to either mislabeled data, or when the data collected\nis missing features necessary to separate the labels. If the data is\nmislabled, it can confuse the model and can result in lower performance\nof the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.checks.integrity import LabelAmbiguity\nfrom deepchecks.tabular import Dataset\nimport pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Data\n=========\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.datasets.classification.phishing import load_data\n\nphishing_dataframe = load_data(as_train_test=False, data_format='Dataframe')\nphishing_dataset = Dataset(phishing_dataframe, label='target', features=['urlLength', 'numDigits', 'numParams', 'num_%20', 'num_@', 'bodyLength', 'numTitles', 'numImages', 'numLinks', 'specialChars'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the Check\n=============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "LabelAmbiguity().run(phishing_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also check label ambiguity on a subset of the features:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "LabelAmbiguity(n_to_show=1).run(phishing_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "LabelAmbiguity(columns=['urlLength', 'numDigits']).run(phishing_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a condition\n==================\n\nNow, we define a condition that enforces that the ratio of ambiguous\nsamples should be 0. A condition is deepchecks\\' way to validate model\nand data quality, and let you know if anything goes wrong.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = LabelAmbiguity()\ncheck.add_condition_ambiguous_sample_ratio_not_greater_than(0)\nresult = check.run(phishing_dataset)\nresult.show(show_additional_outputs=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}