{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:55:52.663977Z",
     "iopub.status.busy": "2022-02-21T11:55:52.663499Z",
     "iopub.status.idle": "2022-02-21T11:55:54.714759Z",
     "shell.execute_reply": "2022-02-21T11:55:54.713860Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from deepchecks.tabular import Dataset\n",
    "from deepchecks.tabular.checks.methodology import ModelInferenceTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:55:54.718353Z",
     "iopub.status.busy": "2022-02-21T11:55:54.718147Z",
     "iopub.status.idle": "2022-02-21T11:55:54.774884Z",
     "shell.execute_reply": "2022-02-21T11:55:54.773785Z"
    }
   },
   "outputs": [],
   "source": [
    "iris = load_iris(as_frame=True)\n",
    "train, test = train_test_split(iris.frame, test_size=0.33, random_state=42)\n",
    "\n",
    "train_ds = Dataset(train, features=iris.feature_names, label='target')\n",
    "test_ds = Dataset(test, features=iris.feature_names, label='target')\n",
    "\n",
    "clf = AdaBoostClassifier().fit(train_ds.data[train_ds.features], train_ds.data[train_ds.label_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:55:54.778768Z",
     "iopub.status.busy": "2022-02-21T11:55:54.778440Z",
     "iopub.status.idle": "2022-02-21T11:55:54.799739Z",
     "shell.execute_reply": "2022-02-21T11:55:54.799094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Model Inference Time</h4><p>Measure model average inference time (in seconds) per sample. <a href=\"https://docs.deepchecks.com/en/0.5.0.dev0/examples/tabular/checks/methodology/model_inference_time.html?utm_source=display_output&utm_medium=referral&utm_campaign=check_link\" target=\"_blank\">Read More...</a></p><h5>Additional Outputs</h5><div>Average model inference time for one sample (in seconds): 0.00013729</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check = ModelInferenceTime()\n",
    "check.run(test_ds, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating check instance with condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:55:54.802543Z",
     "iopub.status.busy": "2022-02-21T11:55:54.802331Z",
     "iopub.status.idle": "2022-02-21T11:55:55.098889Z",
     "shell.execute_reply": "2022-02-21T11:55:55.098132Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Model Inference Time</h4><p>Measure model average inference time (in seconds) per sample. <a href=\"https://docs.deepchecks.com/en/0.5.0.dev0/examples/tabular/checks/methodology/model_inference_time.html?utm_source=display_output&utm_medium=referral&utm_campaign=check_link\" target=\"_blank\">Read More...</a></p><h5>Conditions Summary</h5><style type=\"text/css\">\n",
       "#T_213f1 table {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_213f1 thead {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_213f1 tbody {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_213f1 th {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "#T_213f1 td {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_213f1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_213f1_level0_col0\" class=\"col_heading level0 col0\" >Status</th>\n",
       "      <th id=\"T_213f1_level0_col1\" class=\"col_heading level0 col1\" >Condition</th>\n",
       "      <th id=\"T_213f1_level0_col2\" class=\"col_heading level0 col2\" >More Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_213f1_row0_col0\" class=\"data row0 col0\" ><div style=\"color: red;text-align: center\">âœ–</div></td>\n",
       "      <td id=\"T_213f1_row0_col1\" class=\"data row0 col1\" >Average model inference time for one sample is not greater than 1e-05</td>\n",
       "      <td id=\"T_213f1_row0_col2\" class=\"data row0 col2\" >Found average inference time (in seconds) above threshold: 0.00011651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h5>Additional Outputs</h5><div>Average model inference time for one sample (in seconds): 0.00011651</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check = ModelInferenceTime().add_condition_inference_time_is_not_greater_than(0.00001)\n",
    "check.run(test_ds, clf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84907e5c832b0f30997d577d5af975f753923a883501768793aa42b5515ede32"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
