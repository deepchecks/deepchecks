
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/tabular/checks/methodology/examples/plot_single_feature_contribution_train_test.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_tabular_checks_methodology_examples_plot_single_feature_contribution_train_test.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_tabular_checks_methodology_examples_plot_single_feature_contribution_train_test.py:


Single Feature Contribution Train Test
**************************************
This notebook provides an overview for using and understanding the "Single
Feature Contribution Train Test" check.

**Structure:**

* `What is the purpose of the check? <#what-is-the-purpose-of-the-check>`__
* `Generate data <#generate-data>`__
* `Run the check <#run-the-check>`__
* `Define a condition <#define-a-condition>`__

What is the purpose of the check?
=================================
The check estimates for every feature its ability to predict the label by itself.
This check can help find:

* A potential leakage (between the label and a feature) in both datasets
  - e.g. due to incorrect sampling during data collection. This is a critical
  problem, that will likely stay hidden without this check (as it won't pop
  up when comparing model performance on train and test).
* A strong drift between the the feature-label relation in both datasets,
  possibly originating from a leakage in one of the datasets - e.g. a
  leakage that exists in the training data, but not necessarily in a
  "fresh" dataset, that may have been built differently.

The check is based on calculating the predictive power score (PPS) of each
feature. For more details you can read here `how the PPS is calculated 
<#how-is-the-predictive-power-score-pps-calculated>`__.

What is a problematic result?
-----------------------------
1. Features with a high predictive score - can indicate that there is a leakage
   between the label and the feature, meaning that the feature holds information
   that is somewhat based on the label to begin with.

   For example: a bank uses their loans database to create a model of whether
   a customer will be able to return a loan. One of the features they extract
   is "number of late payments". It is clear this feature will have a very
   strong prediction power on the customer's ability to return his loan,
   but this feature is based on data the bank knows only after the loan is
   given, so it won't be available during the time of the prediction, and is
   a type of leakage.
2. A high difference between the PPS scores of a certain feature in the train
   and in the test datasets - this is an indication for a drift between the
   relation of the feature and the label and a possible leakage in one of 
   the datasets.

   For example: a coffee shop chain trained a model to predict the number of
   coffee cups ordered in a store, and the model was trained on data from a
   specific state, and tested on data from all states. Running the Single
   Feature Contribution check on this split found that there was a high
   difference in the PPS score of the feature "time_in_day" - it had a
   much higher predictive power on the training data than on the test data.
   Investigating this topic led to detection of the problem - the time in
   day was saved in UTC time for all states, which made the feature much
   less indicative for the test data as it had data from several time
   zones (and much more coffee cups are ordered in during the morning/noon
   than during the evening/night time). This was fixed by changing the
   feature to be the time relative to the local time zone, thus fixing its
   predictive power and improving the model's overall performance.

How is the Predictive Power Score (PPS) calculated?
===================================================
The features' predictive score results in a numeric score between 0 (feature
has no predictive power) and 1 (feature can fully predict the label alone).

The process of calculating the PPS is the following:

.. GENERATED FROM PYTHON SOURCE LINES 74-96

1. Extract from the data only the label and the feature being tested
2. Drop samples with missing values
3. Keep 5000 (this is configurable parameter) samples from the data
4. Preprocess categorical columns. For the label using ``sklearn.LabelEncoder``
  and for the feature using ``sklearn.OneHotEncoder``
5. Partition the data with 4-fold cross-validation
6. Train decision tree
7. Compare the trained model's performance with naive model's performance as follows:

  Regression: The naive model always predicts the median of the label column,
  the metric being used is MAE and the PPS calculation is: :math:`1 - \frac{\text{MAE model}}{\text{MAE naive}}`
  Classification: The naive model always predicts the most common class of
  the label column, The metric being used is F1 and the PPS calculation is:
  :math:`\frac{\text{F1 model} - \text{F1 naive}}{1 - \text{F1 naive}}`

Note: all the PPS parameters can be changed by passing to the check the
parameter ``ppscore_params``*

For further information about PPS you can visit the `ppscore github
<https://github.com/8080labs/ppscore>`__ or the following blog post: `RIP correlation.
Introducing the Predictive Power Score
<https://towardsdatascience.com/rip-correlation-introducing-the-predictive-power-score-3d90808b9598>`__

.. GENERATED FROM PYTHON SOURCE LINES 99-103

Generate data
=============
We'll add to a given dataset a direct relation between two features and the label,
in order to see the Single Feature Contribution Train Test check in action.

.. GENERATED FROM PYTHON SOURCE LINES 103-117

.. code-block:: default


    from deepchecks.tabular.datasets.classification.phishing import load_data

    def relate_column_to_label(dataset, column, label_power):
        col_data = dataset.data[column]
        dataset.data[column] = col_data + (dataset.data[dataset.label_name] * col_data.mean() * label_power)
    
    train_dataset, test_dataset = load_data()

    # Transforming 2 features in the dataset given to add correlation to the label 
    relate_column_to_label(train_dataset, 'numDigits', 10)
    relate_column_to_label(train_dataset, 'numLinks', 10)
    relate_column_to_label(test_dataset, 'numDigits', 0.1)








.. GENERATED FROM PYTHON SOURCE LINES 118-120

Run the check
=============

.. GENERATED FROM PYTHON SOURCE LINES 120-125

.. code-block:: default

    from deepchecks.tabular.checks.methodology import SingleFeatureContributionTrainTest

    result = SingleFeatureContributionTrainTest().run(train_dataset=train_dataset, test_dataset=test_dataset)
    result






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">



    <script type="application/vnd.jupyter.widget-state+json">
    {"version_major":2,"version_minor":0,"state":{"1c4fa8a6e35d416088dd506a59e98a04":{"model_name":"VBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","state":{"_dom_classes":[],"children":["IPY_MODEL_9553559794cd4a7dae6433258a81145b","IPY_MODEL_b5c46adc35994587ba9318ce604c9b20","IPY_MODEL_97f4fb13e642434f89ded849fffc486b"],"layout":"IPY_MODEL_a904354156814b6e8baaa7368c99d7dd"}},"9553559794cd4a7dae6433258a81145b":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","state":{"_dom_classes":[],"layout":"IPY_MODEL_a6c80271b5a449cd83faf3bf612b9e82","style":"IPY_MODEL_88efa12c633b492c9dea6bdb21306bfe","value":"<h4>Single Feature Contribution Train-Test</h4><p>    Return the Predictive Power Score of all features, in order to estimate each feature's ability to predict the label. <a href=\"https://docs.deepchecks.com/en/0.6.0.dev1/examples/tabular/checks/methodology/single_feature_contribution_train_test.html?utm_source=display_output&utm_medium=referral&utm_campaign=check_link\" target=\"_blank\">Read More...</a></p><h5>Additional Outputs</h5>"}},"a6c80271b5a449cd83faf3bf612b9e82":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","state":{}},"88efa12c633b492c9dea6bdb21306bfe":{"model_name":"DescriptionStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","state":{}},"b5c46adc35994587ba9318ce604c9b20":{"model_name":"FigureModel","model_module":"jupyterlab-plotly","model_module_version":"^5.6.0","state":{"_config":{"plotlyServerURL":"https://plot.ly"},"_data":[{"marker":{"color":"darkblue"},"name":"Train","text":{"dtype":"float64","shape":[5]},"textposition":"outside","x":["numLinks","numDigits","urlLength","urlIsLive","sscr"],"y":{"dtype":"float64","shape":[5]},"type":"bar","uid":"53c9bebf-eb9b-4f52-9345-45e8a260639e"},{"marker":{"color":"#69b3a2"},"name":"Test","text":{"dtype":"float64","shape":[5]},"textposition":"outside","x":["numLinks","numDigits","urlLength","urlIsLive","sscr"],"y":{"dtype":"float64","shape":[5]},"type":"bar","uid":"297989dc-4866-461c-9f13-052fc2cbb3af"},{"line":{"color":"#aa57b5","width":5},"marker":{"size":15,"symbol":"circle"},"name":"Train-Test Difference (abs)","x":["numLinks","numDigits","urlLength","urlIsLive","sscr"],"y":{"dtype":"float64","shape":[5]},"type":"scatter","uid":"946bd5e6-5dbf-409b-a4d8-f322de97f359"}],"_dom_classes":[],"_js2py_layoutDelta":{},"_js2py_pointsCallback":{},"_js2py_relayout":{},"_js2py_restyle":{},"_js2py_traceDeltas":{},"_js2py_update":{},"_layout":{"barmode":"group","height":500,"legend":{"x":1.0,"y":1.0},"template":{"data":{"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmapgl"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"Predictive Power Score (PPS) - Can a feature predict the label by itself?"},"width":800,"xaxis":{"title":{"text":"Column"}},"yaxis":{"range":[0,1.05],"title":{"text":"Predictive Power Score (PPS)"}}},"_py2js_addTraces":{},"_py2js_animate":{},"_py2js_deleteTraces":{},"_py2js_moveTraces":{},"_py2js_relayout":{},"_py2js_removeLayoutProps":{},"_py2js_removeTraceProps":{},"_py2js_restyle":{},"_py2js_update":{},"_view_count":0},"buffers":[{"encoding":"base64","path":["_data",0,"text","buffer"],"data":"exSuR+F67D9mZmZmZmbuP7gehetRuM4/AAAAAAAAAAAAAAAAAAAAAA=="},{"encoding":"base64","path":["_data",0,"y","buffer"],"data":"MEU+6wZT7D/JZ91ginzuP/jChTWORM4/AAAAAAAAAAAAAAAAAAAAAA=="},{"encoding":"base64","path":["_data",1,"text","buffer"],"data":"AAAAAAAAAADhehSuR+HqP0jhehSuR9E/AAAAAAAAAAAAAAAAAAAAAA=="},{"encoding":"base64","path":["_data",1,"y","buffer"],"data":"AAAAAAAAAADAOX2zh8bqP2RW33DvbdE/AAAAAAAAAAAAAAAAAAAAAA=="},{"encoding":"base64","path":["_data",2,"y","buffer"],"data":"MEU+6wZT7D9IcAFrFbC9P0Cn47BCXaI/AAAAAAAAAAAAAAAAAAAAAA=="}]},"97f4fb13e642434f89ded849fffc486b":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","state":{"_dom_classes":[],"layout":"IPY_MODEL_1961120a51f64120a853e159c3f9372b","style":"IPY_MODEL_07c54331b32949afb05308f73de763a1","value":"<div>The Predictive Power Score (PPS) is used to estimate the ability of a feature to predict the label by itself. (Read more about <a href=https://docs.deepchecks.com/en/stable/examples/tabular/checks/methodology/single_feature_contribution_train_test.html?utm_source=display_output&utm_medium=referral&utm_campaign=check_link target=\"_blank\">Predictive Power Score</a>)</div><div><u>In the graph above</u>, we should suspect we have problems in our data if:</div><div>1. <b>Train dataset PPS values are high</b>:</div><div>Can indicate that this feature's success in predicting the label is actually due to data leakage, </div><div>   meaning that the feature holds information that is based on the label to begin with.</div><div>2. <b>Large difference between train and test PPS</b> (train PPS is larger):</div><div>   An even more powerful indication of data leakage, as a feature that was powerful in train but not in test </div><div>   can be explained by leakage in train that is not relevant to a new dataset.</div><div>3. <b>Large difference between test and train PPS</b> (test PPS is larger):</div><div>   An anomalous value, could indicate drift in test dataset that caused a coincidental correlation to the target label.</div>"}},"1961120a51f64120a853e159c3f9372b":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","state":{}},"07c54331b32949afb05308f73de763a1":{"model_name":"DescriptionStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","state":{}},"a904354156814b6e8baaa7368c99d7dd":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","state":{}}}}
    </script>
    <script type="application/vnd.jupyter.widget-view+json">
    {"version_major":2,"version_minor":0,"model_id":"1c4fa8a6e35d416088dd506a59e98a04"}
    </script>


    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 126-140

Observe the check's output
--------------------------
The check shows the top features with the highest PPS difference in the datasets,
and elaborates how to interpret the results. By default only the top 5 features
are displayed, it can be changed by using the parameter ``n_show_top`` of the check.

In addition to the graphic output, the check also returns a value which includes
all of the information that is needed for defining the conditions for validation.
The value is a dictionary of:

* train - for train dataset for each column the numeric PPS score (0 to 1)
* test - for test dataset for each column the numeric PPS score (0 to 1)
* train-test difference - for each column the difference between the datasets scores,
as ``train - test``

.. GENERATED FROM PYTHON SOURCE LINES 140-143

.. code-block:: default


    result.value





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    {'train': {'numDigits': 0.9527027027027027, 'numLinks': 0.8851351351351351, 'urlLength': 0.23646714795497537, 'month': 0.0, 'ext': 0.0, 'numParams': 0.0, 'num_%20': 0.0, 'num_@': 0.0, 'entropy': 0.0, 'has_ip': 0.0, 'hasHttp': 0.0, 'hasHttps': 0.0, 'urlIsLive': 0.0, 'dsr': 0.0, 'dse': 0.0, 'bodyLength': 0.0, 'numTitles': 0.0, 'numImages': 0.0, 'specialChars': 0.0, 'scriptLength': 0.0, 'sbr': 0.0, 'bscr': 0.0, 'sscr': 0.0}, 'test': {'numDigits': 0.8367346292159752, 'urlLength': 0.2723349191922806, 'month': 0.0, 'ext': 0.0, 'numParams': 0.0, 'num_%20': 0.0, 'num_@': 0.0, 'entropy': 0.0, 'has_ip': 0.0, 'hasHttp': 0.0, 'hasHttps': 0.0, 'urlIsLive': 0.0, 'dsr': 0.0, 'dse': 0.0, 'bodyLength': 0.0, 'numTitles': 0.0, 'numImages': 0.0, 'numLinks': 0.0, 'specialChars': 0.0, 'scriptLength': 0.0, 'sbr': 0.0, 'bscr': 0.0, 'sscr': 0.0}, 'train-test difference': {'bodyLength': 0.0, 'bscr': 0.0, 'dse': 0.0, 'dsr': 0.0, 'entropy': 0.0, 'ext': 0.0, 'hasHttp': 0.0, 'hasHttps': 0.0, 'has_ip': 0.0, 'month': 0.0, 'numDigits': 0.11596807348672755, 'numImages': 0.0, 'numLinks': 0.8851351351351351, 'numParams': 0.0, 'numTitles': 0.0, 'num_%20': 0.0, 'num_@': 0.0, 'sbr': 0.0, 'scriptLength': 0.0, 'specialChars': 0.0, 'sscr': 0.0, 'urlIsLive': 0.0, 'urlLength': -0.035867771237305224}}



.. GENERATED FROM PYTHON SOURCE LINES 144-155

Define a condition
==================
We can define on our check a condition that will validate that our pps scores aren't
too high. The check has 2 possible built-in conditions:
``add_condition_feature_pps_difference_not_greater_than`` - Validate that the difference
in the PPS between train and test is not larger than defined amount (default 0.2)

``add_condition_feature_pps_in_train_not_greater_than`` - Validate that the PPS scores on
train dataset are not exceeding a defined amount (default 0.7)

Let's add the conditions, and re-run the check:

.. GENERATED FROM PYTHON SOURCE LINES 155-159

.. code-block:: default


    check = SingleFeatureContributionTrainTest().add_condition_feature_pps_difference_not_greater_than().add_condition_feature_pps_in_train_not_greater_than()
    result = check.run(train_dataset=train_dataset, test_dataset=test_dataset)
    result.show(show_additional_outputs=False)




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/shiv/Downloads/deepchecks/deepchecks/core/check_result.py:420: UserWarning:

    You are running in a non-interactive python shell. in order to show result you have to use an IPython shell (etc Jupyter)






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  8.758 seconds)


.. _sphx_glr_download_examples_tabular_checks_methodology_examples_plot_single_feature_contribution_train_test.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_single_feature_contribution_train_test.py <plot_single_feature_contribution_train_test.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_single_feature_contribution_train_test.ipynb <plot_single_feature_contribution_train_test.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
