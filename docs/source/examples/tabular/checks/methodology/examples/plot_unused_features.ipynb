{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unused Features\n===============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular import Dataset\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.datasets import load_iris\nfrom deepchecks.tabular.checks import UnusedFeatures\nimport pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load data\n=========\n\nThe dataset is the adult dataset which can be downloaded from the UCI\nmachine learning repository.\n\nDua, D. and Graff, C. (2019). UCI Machine Learning Repository\n\\[<http://archive.ics.uci.edu/ml>\\]. Irvine, CA: University of\nCalifornia, School of Information and Computer Science.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\nfrom sklearn.preprocessing import LabelEncoder\n\nname_data = urlopen('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names')\nlines = [l.decode(\"utf-8\") for l in name_data if ':' in l.decode(\"utf-8\") and '|' not in l.decode(\"utf-8\")]\n\nfeatures = [l.split(':')[0] for l in lines]\nlabel_name = 'income'\n\ncat_features = [l.split(':')[0] for l in lines if 'continuous' not in l]\n\ntrain_df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',\n                       names=features + [label_name])\ntest_df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test',\n                      names=features + [label_name], skiprows=1)\n\ntest_df[label_name] = test_df [label_name].str[:-1]\n\nencoder = LabelEncoder()\nencoder.fit(train_df[label_name])\ntrain_df[label_name] = encoder.transform(train_df[label_name])\ntest_df[label_name] = encoder.transform(test_df[label_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create datasets\n===============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular import Dataset\n\ncat_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', \n                'race', 'sex', 'native-country']\ntrain_ds = Dataset(train_df, label=label_name, cat_features=cat_features)\ntest_ds = Dataset(test_df, label=label_name, cat_features=cat_features)\n\nnumeric_features = list(set(train_ds.features) - set(cat_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification model\n====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import RandomForestClassifier\n\nnumeric_transformer = SimpleImputer()\ncategorical_transformer = Pipeline(\n    steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"encoder\", OrdinalEncoder())]\n)\n\ntrain_ds.features\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, numeric_features),\n        (\"cat\", categorical_transformer, cat_features),\n    ]\n)\n\nmodel = Pipeline(steps=[(\"preprocessing\", preprocessor), (\"model\", RandomForestClassifier(max_depth=5, n_jobs=-1))])\nmodel = model.fit(train_ds.data[train_ds.features], train_ds.data[train_ds.label_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "UnusedFeatures().run(train_ds, test_ds, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**stricter threshold on what features are considered \\\"high variance\\\"**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "UnusedFeatures(feature_variance_threshold=1.5).run(train_ds, test_ds, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**All features are considered important**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "UnusedFeatures(feature_importance_threshold=0).run(train_ds, test_ds, model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}