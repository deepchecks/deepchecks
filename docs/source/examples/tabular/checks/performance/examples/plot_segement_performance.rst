
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/tabular/checks/performance/examples/plot_segement_performance.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_tabular_checks_performance_examples_plot_segement_performance.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_tabular_checks_performance_examples_plot_segement_performance.py:


Segment Performance
*******************

.. GENERATED FROM PYTHON SOURCE LINES 8-14

Load data
=========
The dataset is the adult dataset which can be downloaded from the UCI machine learning repository.

Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml].
Irvine, CA: University of California, School of Information and Computer Science.

.. GENERATED FROM PYTHON SOURCE LINES 14-39

.. code-block:: default


    import pandas as pd
    from urllib.request import urlopen
    from sklearn.preprocessing import LabelEncoder

    name_data = urlopen('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names')
    lines = [l.decode("utf-8") for l in name_data if ':' in l.decode("utf-8") and '|' not in l.decode("utf-8")]

    features = [l.split(':')[0] for l in lines]
    label_name = 'income'

    cat_features = [l.split(':')[0] for l in lines if 'continuous' not in l]

    train_df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',
                           names=features + [label_name])
    val_df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test',
                          names=features + [label_name], skiprows=1)

    val_df[label_name] = val_df [label_name].str[:-1]

    encoder = LabelEncoder()
    encoder.fit(train_df[label_name])
    train_df[label_name] = encoder.transform(train_df[label_name])
    val_df[label_name] = encoder.transform(val_df[label_name])



.. rst-class:: sphx-glr-script-out

.. code-block:: pytb

    Traceback (most recent call last):
      File "/home/shiv/Downloads/deepchecks/docs/source/examples/tabular/checks/performance/source/plot_segement_performance.py", line 19, in <module>
        name_data = urlopen('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names')
      File "/usr/lib/python3.8/urllib/request.py", line 222, in urlopen
        return opener.open(url, data, timeout)
      File "/usr/lib/python3.8/urllib/request.py", line 525, in open
        response = self._open(req, data)
      File "/usr/lib/python3.8/urllib/request.py", line 542, in _open
        result = self._call_chain(self.handle_open, protocol, protocol +
      File "/usr/lib/python3.8/urllib/request.py", line 502, in _call_chain
        result = func(*args)
      File "/usr/lib/python3.8/urllib/request.py", line 1383, in http_open
        return self.do_open(http.client.HTTPConnection, req)
      File "/usr/lib/python3.8/urllib/request.py", line 1357, in do_open
        raise URLError(err)
    urllib.error.URLError: <urlopen error [Errno 110] Connection timed out>




.. GENERATED FROM PYTHON SOURCE LINES 40-42

Create Dataset
==============

.. GENERATED FROM PYTHON SOURCE LINES 42-52

.. code-block:: default


    from deepchecks.tabular import Dataset

    cat_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 
                    'race', 'sex', 'native-country']
    train_ds = Dataset(train_df, label=label_name, cat_features=cat_features)
    validation_ds = Dataset(val_df, label=label_name, cat_features=cat_features)

    numeric_features = list(set(train_ds.features) - set(cat_features))


.. GENERATED FROM PYTHON SOURCE LINES 53-55

Classification Model
====================

.. GENERATED FROM PYTHON SOURCE LINES 55-82

.. code-block:: default


    from sklearn.pipeline import Pipeline
    from sklearn.impute import SimpleImputer
    from sklearn.compose import ColumnTransformer
    from sklearn.preprocessing import OrdinalEncoder
    from sklearn.ensemble import RandomForestClassifier

    numeric_transformer = SimpleImputer()
    categorical_transformer = Pipeline(
        steps=[("imputer", SimpleImputer(strategy="most_frequent")), ("encoder", OrdinalEncoder())]
    )

    train_ds.features
    preprocessor = ColumnTransformer(
        transformers=[
            ("num", numeric_transformer, numeric_features),
            ("cat", categorical_transformer, cat_features),
        ]
    )

    model = Pipeline(
        steps=[
            ("preprocessing", preprocessor), 
            ("model", RandomForestClassifier(max_depth=5, n_jobs=-1))
        ]
    ).fit(train_ds.data[train_ds.features], train_ds.data[train_ds.label_name])


.. GENERATED FROM PYTHON SOURCE LINES 83-86

.. code-block:: default


    model


.. GENERATED FROM PYTHON SOURCE LINES 87-91

.. code-block:: default


    from deepchecks.tabular.checks.performance import SegmentPerformance

    SegmentPerformance(feature_1='workclass', feature_2='hours-per-week').run(validation_ds, model)


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  9.893 seconds)


.. _sphx_glr_download_examples_tabular_checks_performance_examples_plot_segement_performance.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_segement_performance.py <plot_segement_performance.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_segement_performance.ipynb <plot_segement_performance.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
