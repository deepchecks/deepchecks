{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Export Outputs to JSON\n======================\n\nIn this guide, we will demonstrate how to export the Check\\'s and the\nSuite\\'s output to JSON format.\n\nThis enables to use the exported results as a serializeable object that\ncan later be shared or reviewed in other Python scopes, and also enables\nworking with the check\\'s output (name, parameters, result value and\nresult display) not only in a visual manner (e.g. by parsing the output\nJSON).\n\n**Structure:**\n\n-   [Load Data](#load-data)\n-   [Run a Check](#run-a-check)\n-   [Export Check to\n    JSON](#export-a-check-s-output-checkresult-to-a-json-format)\n-   [Export Suite to\n    JSON](#exporting-a-suite-s-output-suiteresult-to-json)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Data\n=========\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.datasets.classification import iris\n\ntrain_dataset, test_dataset = iris.load_data()\nmodel = iris.load_fitted_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run a Check\n===========\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.checks import ModelErrorAnalysis\n\nresult = ModelErrorAnalysis().add_condition_segments_performance_relative_difference_not_greater_than(\\\n                                ).run(train_dataset, test_dataset, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe CheckResult Display and Value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Export a Check\\'s Output (CheckResult) to a JSON Format\n=======================================================\n\nSerialization of the output to a JSON format is possible using the\n`to_json` function. This function takes the check outputs and serializes\nit to a JSON string.\n\nThe format of the check\\'s output json includes all of the info required\nto reconstruct the check run and it\\'s output: it\\'s name, the\nparameters the check receives, one sentence summary of the check\\'s\npurpose, it\\'s result value and a json of the data relevant for\ndisplaying the check\\'s outputs.\n\nSee Check JSON Structure\n------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.core import CheckResult\n\nhelp(CheckResult.to_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# get output JSON\nserialized_output = result.to_json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import json\n\n# note - conditions_table key exists only if there are conditions that were defined on check\njson.loads(serialized_output).keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe JSON Output\n===================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "json.loads(serialized_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display the CheckResult Output from a JSON\n==========================================\n\nThe serialized JSON can be used to reproduce the run in other Python\nscopes, by using the `display_from_json` function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "CheckResult.display_from_json(serialized_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exporting a Suite\\'s Output (SuiteResult) to JSON\n=================================================\n\nRun Suite and Save to JSON\n--------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.suites import full_suite\n\nsuite = full_suite()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "suite_result = suite.run(train_dataset=train_dataset, test_dataset=test_dataset, model=model)\nsuite_json = suite_result.to_json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe Suite\\'s JSON Strucutre\n===============================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.core import SuiteResult\n\nhelp(SuiteResult.to_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suite name:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "json.loads(suite_json)['name']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results is an array of CheckResult JSON\\'s, let\\'s see how many checks\nran in suite:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "len(json.loads(suite_json)['results'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets observe a specific check\\'s output, which is similar to the [Check\noutput\\'s JSON\nStructure](#export-a-check-s-output-checkresult-to-a-json-format) we saw\nbefore for each check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "json.loads(json.loads(suite_json)['results'][0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}