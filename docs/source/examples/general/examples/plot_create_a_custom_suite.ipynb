{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a Custom Suite\n=====================\n\nA suite is a list of checks that will run one after the other, and its\nresults will be displayed together.\n\nTo customize a suite, we can either:\n\n-   [Create new custom suites](#create-a-new-suite), by choosing the\n    checks (and the optional conditions) that we want the suite to have.\n-   [Modify a built-in suite](#modify-an-existing-suite) by adding\n    and/or removing checks and conditions, to adapt it to our needs.\n\nCreate a New Suite\n------------------\n\nLet\\'s say we want to create our custom suite, mainly with various\nperformance checks, including\n`PerformanceReport(), TrainTestDifferenceOverfit()` and several more.\n\nFor assistance in understanding which checks are implemented and can be\nincluded, we suggest using any of:\n\n-   [API Reference](/api/index.html)\n-   [Tabular checks demonstration\n    notebooks](/examples/tabular/checks/test_autoexamples/index.html)\n-   [Computer vision checks demonstration\n    notebooks](/examples/vision/checks/test_autoexamples/index.html)\n-   Built-in suites (by printing them to see which checks they include)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# importing all existing checks for demonstration simplicity\nfrom deepchecks.tabular.checks import *\nfrom deepchecks.tabular import Suite\nfrom sklearn.metrics import precision_score, recall_score, make_scorer\n\n# The Suite's first argument is its name, and then all of the check objects.\n# Some checks can receive arguments when initialized (all check arguments have default values)\n# Each check can have an optional condition(/s)\n# Multiple conditions can be applied subsequentially\nnew_custom_suite = Suite('Simple Suite For Model Performance',\n    ModelInfo(),\n    # use custom scorers for performance report:\n    PerformanceReport().add_condition_train_test_relative_degradation_not_greater_than(threshold=0.15\\\n                     ).add_condition_test_performance_not_less_than(0.8),\n    ConfusionMatrixReport(),\n    SimpleModelComparison(simple_model_type='constant', \\\n                          alternative_scorers={'Recall (Multiclass)': make_scorer(recall_score, average=None), \\\n                                               'Precision (Multiclass)': make_scorer(precision_score, average=None)} \\\n                         ).add_condition_gain_not_less_than(0.3)\n    )\n# Let's see the suite:\nnew_custom_suite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*TIP: the auto-complete may not work from inside a new suite definition,\nso if you want to use the auto-complete to see the arguments a check\nreceive or the built-in conditions it has, try doing it outside of the\nsuite\\'s initialization.*\n\n*For example, to see a check\\'s built-in conditions, type in a new cell:\n\\`\\`NameOfDesiredCheck().add\\_condition\\_\\`\\` and then check the\nauto-complete suggestions (using Shift + Tab), to discover the built-in\nchecks.*\n\nAdditional Notes about Conditions in a Suite\n============================================\n\n-   Checks in the built-in suites come with pre-defined conditions, and\n    when building your custom suite you should choose which conditions\n    to add.\n-   Most check classes have built-in methods for adding monditions.\n    These apply to the naming convention `add_condition_...`, which\n    enables adding a condition logic to parse the check\\'s results.\n-   Each check instance can have several conditions or none. Each\n    condition will be evaluated separately.\n-   The pass (\u2713) / fail (\u2716) / insight (!) status of the conditions,\n    along with the condition\\'s name and extra info will be displayed in\n    the suite\\'s Conditions Summary.\n-   Most conditions have configurable arguments that can be passed to\n    the condition while adding it.\n-   For more info about conditions, check out [Configure a\n    Condition](plot_configure_check_conditions.html).\n\nRun the Suite\n-------------\n\nThis is simply done by calling the `run()` method of the suite.\n\nTo see that in action, we\\'ll need datasets and a model.\n\nLet\\'s quickly load a dataset and train a simple model for the sake of\nthis demo\n\nLoad Datasets and Train a Simple Model\n======================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# General imports\nimport pandas as pd\nimport numpy as np\nnp.random.seed(22)\n\nfrom deepchecks.tabular.datasets.classification import iris\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\n# Load pre-split Datasets\ntrain_dataset, test_dataset = iris.load_data(as_train_test=True)\nlabel_col = 'target'\n\n# Train Model\nrf_clf = RandomForestClassifier()\nrf_clf.fit(train_dataset.data[train_dataset.features],\n           train_dataset.data[train_dataset.label_name]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run Suite\n=========\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "new_custom_suite.run(model=rf_clf, train_dataset=train_dataset, test_dataset=test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modify an Existing Suite\n========================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.suites import train_test_leakage\n\ncustomized_suite = train_test_leakage()\n\n# let's check what it has:\ncustomized_suite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# and modify it by removing a check by index:\ncustomized_suite.remove(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.checks import UnusedFeatures\n\n# and add a new check with a condition:\ncustomized_suite.add(\n    UnusedFeatures().add_condition_number_of_high_variance_unused_features_not_greater_than())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# lets remove all condition for the SingleFeatureContributionTrainTest:\ncustomized_suite[3].clean_conditions()\n\n# and update the suite's name:\ncustomized_suite.name = 'New Data Leakage Suite'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# and now we can run our modified suite:\ncustomized_suite.run(train_dataset, test_dataset, rf_clf)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}