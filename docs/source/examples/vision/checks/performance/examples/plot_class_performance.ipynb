{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Class Performance Check\n=======================\n\nThis notebooks provides an overview for using and understanding the\nclass performance check.\n\n**Structure:**\n\n-   [What is the purpose of the\n    check?](#what-is-the-purpose-of-the-check)\n-   [Classification](#classification-performance-report)\n    -   [Generate data & model](#generate-data-and-model)\n    -   [Run the check](#run-the-check)\n-   [Object Detection](#object-detection-class-performance)\n    -   [Generate data & model](#id1)\n    -   [Run the check](#id2)\n\nWhat is the purpose of the check?\n---------------------------------\n\nThe class performance check evaluates several metrics on the given model\nand data and returns all of the results in a single check. For each task\ntype it has default metrics (e.g. precision and recall per class for\nclassification, and AP per class for object detection).\n\nIn addition to the default metrics, the check supports custom metrics\nthat should be implemented using the\n[torch.ignite.Metric](https://pytorch.org/ignite/metrics.html#how-to-create-a-custom-metric).\nThese can be passed as a list using the alternative\\_metrics parameter\nof the check, which will override the default metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports\n=======\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.checks.performance import ClassPerformance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification Performance Report\n=================================\n\nGenerate data and model:\n------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.datasets.classification import mnist\n\nmnist_model = mnist.load_model()\ntrain_ds = mnist.load_dataset(train=True, object_type='VisionData')\ntest_ds = mnist.load_dataset(train=False, object_type='VisionData')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = ClassPerformance()\ncheck.run(train_ds, test_ds, mnist_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Object Detection Class Performance\n==================================\n\nFor object detection tasks - the default metric that is being calculated\nit the Average Precision. The definition of the Average Precision is\nidentical to how the COCO dataset defined it - mean of the average\nprecision per class, over the range \\[0.5, 0.95, 0.05\\] of IoU\nthresholds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom deepchecks.vision.datasets.detection import coco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate Data and Model\n=======================\n\nWe generate a sample dataset of 128 images from the [COCO\ndataset](https://cocodataset.org/#home), and using the [YOLOv5\nmodel](https://github.com/ultralytics/yolov5).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "yolo = coco.load_model(pretrained=True)\n\ntrain_ds = coco.load_dataset(train=True, object_type='VisionData')\ntest_ds = coco.load_dataset(train=False, object_type='VisionData')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = ClassPerformance(show_only='best')\ncheck.run(train_ds, test_ds, yolo)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}