{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e767e792",
   "metadata": {},
   "source": [
    "# Mean Average Precision Report\n",
    "\n",
    "This notebooks provides an overview for using and understanding the mean average precision report check.\n",
    "\n",
    "**Structure:**\n",
    "\n",
    "- [What is the purpose of the check?](#purpose)\n",
    "- [Object Detection](#obj_det)\n",
    "    - [Generate data & model](#generate_o)\n",
    "    - [Defining the Prediction Formatter](#pred_format_o)\n",
    "    - [Run the check](#run_check_o)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba23c4",
   "metadata": {},
   "source": [
    "## What is the purpose of the check? <a name='purpose'></a>\n",
    "\n",
    "The mean average precision report evaluates the mean average precision metric on the given model and data. \n",
    "The check only works on object detection as it computes the value with the IoU and Area size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c7ee01-6999-465e-a318-56570b008526",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bef717-c573-43ec-8589-a81ecc08f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.vision.base import VisionData\n",
    "from deepchecks.vision.checks.performance import MeanAveragePrecisionReport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb14d7f9-4e40-4f81-8653-6625afbe8bbd",
   "metadata": {},
   "source": [
    "## Object Detection Class Performance  <a name='obj_det'></a>\n",
    "\n",
    "For object detection tasks - the default metric that is being calculated it the Average Precision. The definition of the Average Precision is identical to how the COCO dataset defined it - mean of the average precision per class, over the range [0.5, 0.95, 0.05] of IoU thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6706c-1cb8-44a3-b40e-80c5d93bbe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from deepchecks.vision.utils.detection_formatters import DetectionLabelFormatter, DetectionPredictionFormatter\n",
    "from deepchecks.vision.datasets.detection import coco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb58d486",
   "metadata": {},
   "source": [
    "### Generate Data and Model <a name='generate_o'></a>\n",
    "\n",
    "We generate a sample dataset of 128 images from the [COCO dataset](https://cocodataset.org/#home), and using the [YOLOv5 model](https://github.com/ultralytics/yolov5).\n",
    "\n",
    "For the label formatter - our dataset returns exactly the accepted format, so our formatting function is the simple `lambda x: x` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a105788-e0b1-42cc-94cc-fe0292fdaa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = coco.load_model(pretrained=True)\n",
    "\n",
    "coco_test_loader = coco.load_dataset(train=False)\n",
    "\n",
    "test_ds = VisionData(coco_test_loader, label_transformer=DetectionLabelFormatter(coco.yolo_label_formatter), num_classes=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a782b1fb",
   "metadata": {},
   "source": [
    "### Defining the prediction formatter <a name='pred_format_o'></a>\n",
    "The COCO module implemented in deepchecks already contains a transformation function to convert the yolo detection to the correct format of [x, y, w, h, confidence, class_id]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42faaba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.vision.utils.detection_formatters import DetectionPredictionFormatter\n",
    "\n",
    "det_formatter = DetectionPredictionFormatter(coco.yolo_prediction_formatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1008328",
   "metadata": {},
   "source": [
    "### Run the check <a name='run_check_o'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81821ee9-2c46-446a-92fc-142b855f833e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check = MeanAveragePrecisionReport()\n",
    "result = check.run(test_ds, yolo, prediction_formatter=det_formatter)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376fefe0-79a8-438d-8105-945c03964cea",
   "metadata": {},
   "source": [
    "### Observe the checkâ€™s output\n",
    "\n",
    "The result value is a dataframe that has the average precision score per each area range and IoU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5d0e0-68ff-4536-a6d6-3f8c3cd0b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f911b-a833-40d8-b797-9c05edf695d5",
   "metadata": {},
   "source": [
    "## Define a condition\n",
    "\n",
    "We can define a condition that enforce our model's average precision score is not less than a given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b389e9c-a0f7-4676-891d-f1d27a717cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = MeanAveragePrecisionReport().add_condition_test_average_precision_not_less_than(0.3)\n",
    "result = check.run(test_ds, yolo, prediction_formatter=det_formatter)\n",
    "result.show(show_additional_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee17bbe-ddc8-4ec8-9c33-677df25b9464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "test1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
