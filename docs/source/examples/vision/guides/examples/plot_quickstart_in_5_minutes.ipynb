{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quickstart in 5 minutes\n=======================\n\nIn order to run deepchecks.vision, you need two simple things. First,\nyou\\'ll need you data and model. Second, you may need to write short\nformatter functions that will let us know how to translate your data and\nlabels into common formats the package can understand. For model and\ndata, you will need:\n\n-   Your train and test data (each a pytorch dataloader)\n-   (optional) A model object, for which calling `model(batch)` for a\n    dataloader batch returns the batch predictions. Required for running\n    checks that need the model\\'s predictions for running.\n\nTo run your first suite on your data and model, you need only a few\nlines of code, that start here: [Define a VisionData\nObject](#fefine-a-visiondata-object).\n\n``` {.sourceCode .python}\n# If you don't have deepchecks installed yet:\nimport sys\n!{sys.executable} -m pip install deepchecks -U --quiet #--user\n```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\nfrom typing import Union, List\n\nimport torch\nimport numpy as np\n\nfrom deepchecks.vision.detection_data import DetectionData\nfrom deepchecks.vision.datasets.detection import coco\nfrom deepchecks.vision import VisionData\nfrom deepchecks.vision.suites import full_suite\nfrom deepchecks.vision.checks import TrainTestLabelDrift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Data and Model\n===================\n\nFor the purpose of this guide we'll use the [coco 128\ndataset](https://www.kaggle.com/ultralytics/coco128) and the ultralytics\n[yolov5s](https://pytorch.org/hub/ultralytics_yolov5/#load-from-pytorch-hub)\nobject detection model, both already included in the deepchecks package:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\nyolo = coco.load_model(pretrained=True, device=device)\ncoco_train_loader = coco.load_dataset(train=True)\ncoco_test_loader = coco.load_dataset(train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement a Data Object\n=======================\n\nDeepchecks' checks and suites expect a data object that is specific for\nthe task type. These data objects are used to load a preprocess data for\nthe particular task type, and all inherit from [Vision\nData](../../../api/generated/deepchecks.vision.VisionData.rst).\n\nFor classification - the data class should inherit from\n[ClassificationData\n\\<../../../api/generated/deepchecks.vision.ClassificationData.rst]{.title-ref}\\_\\_,\nand for detection from\n[DetectionData](../../../api/generated/deepchecks.vision.DetectionData.rst).\n\nBecause our example here is a detection problem, we will create a class\ninherited from the DetectionData class, and will implement the following\nrequried functions:\n\n\\- batch\\_to\\_images - Transform a batch of data to images in the\naccpeted format. For more info refer to the [API\nreference](../../../api/generated/deepchecks.vision.DetectionData.batch_to_images.rst).\n- batch\\_to\\_labels - Extract the labels from a batch of data. For more\ninfo refer to the [API\nreference](../../../api/generated/deepchecks.vision.DetectionData.batch_to_labels.rst).\n- infer\\_on\\_batch - Return the predictions of the model on a batch of\ndata. For more info refer to the [API\nreference](../../../api/generated/deepchecks.vision.DetectionData.infer_on_batch.rst).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class COCOData(DetectionData):\n\n    def batch_to_labels(self, batch) -> Union[List[torch.Tensor], torch.Tensor]:\n        def move_class(tensor):\n            return torch.index_select(tensor, 1, torch.LongTensor([4, 0, 1, 2, 3]).to(tensor.device)) \\\n                if len(tensor) > 0 else tensor\n\n        return [move_class(tensor) for tensor in batch[1]]\n\n    def infer_on_batch(self, batch, model, device) -> Union[List[torch.Tensor], torch.Tensor]:\n        return_list = []\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(action='ignore', category=UserWarning)\n\n            predictions: 'ultralytics.models.common.Detections' = model.to(device)(batch[0])  # noqa: F821\n\n            # yolo Detections objects have List[torch.Tensor] xyxy output in .pred\n            for single_image_tensor in predictions.pred:\n                pred_modified = torch.clone(single_image_tensor)\n                pred_modified[:, 2] = pred_modified[:, 2] - pred_modified[:, 0]  # w = x_right - x_left\n                pred_modified[:, 3] = pred_modified[:, 3] - pred_modified[:, 1]  # h = y_bottom - y_top\n                return_list.append(pred_modified)\n\n        return return_list\n\n    def batch_to_images(self, batch) -> List[np.ndarray]:\n        return [np.array(x) for x in batch[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we will initialize instances of our COCOData class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_ds = COCOData(coco_train_loader, label_map=coco.LABEL_MAP)\ntest_ds = COCOData(coco_test_loader, label_map=coco.LABEL_MAP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run a Deepchecks Suite\n======================\n\nRun the full suite\n------------------\n\nUse the `full_suite` that is a collection of (most of) the prebuilt\nchecks. Check out the [when should you use deepchecks\nguide](../../../user-guide/concepts/when_should_you_use.rst) for some\nmore info about the existing suites and when to use them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "suite = full_suite()\n\nresult = suite.run(train_dataset=train_ds, test_dataset=test_ds, model=yolo, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to view the results, the result object can be exported to an\nhtml file, as demonstrated here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.save_as_html('full_suite_result.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the code is running inside a jupyter notebook, the result can also be\nviewed by simply running `result` inside a notebook cell, as\ndemonstrated here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run a Deepchecks Check\n======================\n\nIf you want to run a specific check, you can just import it and run it\ndirectly.\n\nCheck out the [Check Demonstrations](../index.rst) in the examples or\nthe [API Reference](../../../api/index.rst) for more info about the\nexisting checks and their parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = TrainTestLabelDrift()\nresult = check.run(train_ds, test_ds, device=device)\nresult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and also inspect the result value which has a check-dependant structure:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(result.value)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}