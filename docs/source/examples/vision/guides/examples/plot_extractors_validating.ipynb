{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test Your Extractors In Development\n===================================\n\n\\\"Extractors\\\" are used to transform the structure of your data to the\nstructure required for deepchecks. To help ensure your extractors work\nas intended, deepchecks has built-in helper functions for extractor\nvalidation. This guide will demonstrate how to use this helper function\nto implement formatters for your own data, step by step.\n\n**Structure:**\n\n-   [Load data and model](#load-data-and-model)\n-   [Create simple DetectionData\n    object](#create-simple-detectiondata-object)\n-   [Running the extractors\n    validation](#running-the-extractors-validation)\n-   [Understand validation results](#understand-validation-results)\n-   [The end result](#the-end-result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load data and model\n===================\n\nIn the first step we load the DataLoader and our model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.datasets.detection.coco import load_dataset, load_model\n\ndata_loader = load_dataset(train=False, batch_size=1000, object_type='DataLoader')\nmodel = load_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create simple DetectionData object\n==================================\n\nIn the second step since this is an object detection task we will\noverride a DetectionData object with simple extracting functions. We\nknow our DataLoader and model\\'s output are not in the format expected\nby deepchecks, so when we validate them on our data we will see in the\nresults the functions we overrided are not passing, and then we will\nimplement a correct functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.detection_data import DetectionData\n\nclass CocoDetectionData(DetectionData):\n    def batch_to_images(self, batch):\n        return batch[0]\n\n    def batch_to_labels(self, batch):\n        return batch[1]\n\n    def infer_on_batch(self, batch, model, device):\n        return model.to(device)(batch[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the extractors validation\n=================================\n\nNow we will load our validate function and see the results while running\nthe extractors on our data. The function will print for us the\nvalidation results. At the end, if all your extractors are valid the\noutput should look in [this](#The-end-result).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.utils.validation import validate_extractors\n\nvalidate_extractors(CocoDetectionData(data_loader), model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Understand validation results\n=============================\n\nWhen looking at the result first thing we see is that it\\'s separated\ninto 2 parts.\n\nFirst one is about the structure we expect to get. This validation is\nautomatic since it\\'s purely technical and doesn\\'t check content\ncorrectness. For example, in our validation above we see that the label\nextractor is passing, meaning the labels are returning in the expected\nformat. Second part is about the content, which can\\'t be automatically\nvalidated and requires your attention. This part includes looking\nvisually at data outputted by the formatters to validate it is right. In\nthe validation above we see a list of classes that doesn\\'t seem to make\nsense. This is because although our labels are in the right structure,\nthe content inside is not valid.\n\nWe know that the classes in our data are represented by class id which\nis an int, therefore we understand the labels does not contain the data\nin the right order. For the next step we\\'ll fix the label extractor and\nthen validate again:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\nclass CocoDetectionData(DetectionData):\n    def batch_to_labels(self, batch):\n        # Translate labels to deepchecks format.\n        # the label_id here is in the last position of the tensor, and the DetectionLabelFormatter expects it\n        # at the first position.\n        formatted_labels = []\n        for tensor in batch[1]:\n            tensor = torch.index_select(tensor, 1, torch.LongTensor([4, 0, 1, 2, 3])) if len(tensor) > 0 else tensor\n            formatted_labels.append(tensor)\n        return formatted_labels\n\n    def batch_to_images(self, batch):\n        return batch[0]\n\n    def infer_on_batch(self, batch, model, device):\n        return model.to(device)(batch[0])\n\nvalidate_extractors(CocoDetectionData(data_loader), model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can see in the content section that our classes are indeed as we\nexpect them to be, class ids of type int. Now we can continue and fix\nthe prediction extractor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class CocoDetectionData(DetectionData):\n    def infer_on_batch(self, batch, model, device):\n        # Convert from yolo Detections object to List (per image) of Tensors of the shape [N, 6]\"\"\"\n        return_list = []\n        predictions = model.to(device)(batch[0])\n\n        # yolo Detections objects have List[torch.Tensor] xyxy output in .pred\n        for single_image_tensor in predictions.pred:\n            return_list.append(single_image_tensor)\n\n        return return_list\n\n    # using the same label extractor\n    def batch_to_labels(self, batch):\n        # Translate labels to deepchecks format.\n        # the label_id here is in the last position of the tensor, and the DetectionLabelFormatter expects it\n        # at the first position.\n        formatted_labels = []\n        for tensor in batch[1]:\n            tensor = torch.index_select(tensor, 1, torch.LongTensor([4, 0, 1, 2, 3])) if len(tensor) > 0 else tensor\n            formatted_labels.append(tensor)\n        return formatted_labels\n    \n    def batch_to_images(self, batch):\n        return batch[0]\n\nvalidate_extractors(CocoDetectionData(data_loader), model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now our prediction formatter also have valid structure. But in order to\nreally validate it we also need visual assertion and for that we need\nthe image extractor to work.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nclass CocoDetectionData(DetectionData):\n    def batch_to_images(self, batch):\n        # Yolo works on PIL and ImageFormatter expects images as numpy arrays\n        return [np.array(x) for x in batch[0]]\n\n    # using the same prediction extractor\n    def infer_on_batch(self, batch, model, device):\n        # Convert from yolo Detections object to List (per image) of Tensors of the shape [N, 6]\"\"\"\n        return_list = []\n        predictions = model.to(device)(batch[0])\n\n        # yolo Detections objects have List[torch.Tensor] xyxy output in .pred\n        for single_image_tensor in predictions.pred:\n            return_list.append(single_image_tensor)\n\n        return return_list\n\n    # using the same label extractor\n    def batch_to_labels(self, batch):\n        # Translate labels to deepchecks format.\n        # the label_id here is in the last position of the tensor, and the DetectionLabelFormatter expects it\n        # at the first position.\n        formatted_labels = []\n        for tensor in batch[1]:\n            tensor = torch.index_select(tensor, 1, torch.LongTensor([4, 0, 1, 2, 3])) if len(tensor) > 0 else tensor\n            formatted_labels.append(tensor)\n        return formatted_labels\n\n\nvalidate_extractors(CocoDetectionData(data_loader), model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that that image extractor is valid it displays for us visually the\nlabel and prediction. When we look at the label we see it is correct,\nbut when we look at the prediction something is broken.\n\nWe need to fix the prediction so the prediction will be returned in \\[x,\ny, w, h, confidence, class\\] format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class CocoDetectionData(DetectionData):\n    def infer_on_batch(self, batch, model, device):\n        # Convert from yolo Detections object to List (per image) of Tensors of the shape [N, 6] with each row being \n        # [x, y, w, h, confidence, class] for each bbox in the image.\"\"\"\n        return_list = []\n        predictions = model.to(device)(batch[0])\n\n        # yolo Detections objects have List[torch.Tensor] xyxy output in .pred\n        for single_image_tensor in predictions.pred:\n            pred_modified = torch.clone(single_image_tensor)\n            pred_modified[:, 2] = pred_modified[:, 2] - pred_modified[:, 0]  # w = x_right - x_left\n            pred_modified[:, 3] = pred_modified[:, 3] - pred_modified[:, 1]  # h = y_bottom - y_top\n            return_list.append(pred_modified)\n\n        return return_list\n\n    # using the same label extractor\n    def batch_to_labels(self, batch):\n        # Translate labels to deepchecks format.\n        # the label_id here is in the last position of the tensor, and the DetectionLabelFormatter expects it\n        # at the first position.\n        formatted_labels = []\n        for tensor in batch[1]:\n            tensor = torch.index_select(tensor, 1, torch.LongTensor([4, 0, 1, 2, 3])) if len(tensor) > 0 else tensor\n            formatted_labels.append(tensor)\n        return formatted_labels\n\n    # using the same image extractor\n    def batch_to_images(self, batch):\n        # Yolo works on PIL and ImageFormatter expects images as numpy arrays\n        return [np.array(x) for x in batch[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The end result\n==============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "validate_extractors(CocoDetectionData(data_loader), model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}